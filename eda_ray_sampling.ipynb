{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Exploratory Data Analysis*\n",
    "\n",
    "# Visualizing the Sampling Strategy along Rays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import FancyArrowPatch, FancyArrow, ArrowStyle\n",
    "from mpl_toolkits.mplot3d import proj3d\n",
    "from matplotlib.lines import Line2D\n",
    "import torch\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from run_dnerf_helpers import get_rays\n",
    "from load_deepdeform import load_deepdeform_data, pose_spiral\n",
    "from utils import Arrow3D, draw_transformed, draw_cam, draw_ray\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the validation logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading rays from logs/human_10_mse_old_lengths/step_050000_ray_debug.pickle\n",
      "Loading rays from logs/human_10_mse_old_lengths/step_100000_ray_debug.pickle\n",
      "Loading rays from logs/human_10_mse_old_lengths/step_150000_ray_debug.pickle\n",
      "Loading rays from logs/human_10_mse_old_lengths/step_200000_ray_debug.pickle\n",
      "Loading rays from logs/human_10_mse_old_lengths/step_250000_ray_debug.pickle\n",
      "Loading rays from logs/human_10_mse_old_lengths/step_300000_ray_debug.pickle\n",
      "Loading rays from logs/human_10_mse_old_lengths/step_350000_ray_debug.pickle\n",
      "Logged items (shape/value):\n",
      "\t\trays_o\t(240, 320, 3)\n",
      "\t\trays_d\t(240, 320, 3)\n",
      "\t\trgb_map\t(240, 320, 3)\n",
      "\t\tdepth_map\t(240, 320, 1)\n",
      "\t\tz_coarse\t(240, 320, 64)\n",
      "\t\tz_fine\t(240, 320, 128)\n",
      "\t\tc2w\t(3, 4)\n",
      "\t\tnear\t0.10000000149011612\n",
      "\t\tfar\t14.251960754394531\n"
     ]
    }
   ],
   "source": [
    "# path = \"logs/human_06_mse\"\n",
    "# path = \"logs/human_07_mse_dgs\"\n",
    "# path = \"logs/human_08_mse_003\"\n",
    "path = \"logs/human_10_mse_old_lengths/\"\n",
    "# path = \"logs/human_11_mse_old_sampling_code/\"\n",
    "\n",
    "sampling_strategy = \"Hierarchical Sampling\"\n",
    "with open(os.path.join(path, \"args.txt\"), \"r\") as f:\n",
    "    for line in f:\n",
    "        if \"use_depth_guided_sampling = True\" in line:\n",
    "            sampling_strategy = \"Depth Guided Sampling\"\n",
    "\n",
    "ray_pickles = sorted([p for p in os.listdir(path) if \".pickle\" in p])\n",
    "frame_logs = []\n",
    "for ray_pickle in ray_pickles:\n",
    "    load_p = os.path.join(path, ray_pickle)\n",
    "    with open(load_p, \"rb\") as f:\n",
    "        print(\"Loading rays from \" + load_p)\n",
    "        frame_logs.append(pickle.load(f))\n",
    "\n",
    "print(\"Logged items (shape/value):\")\n",
    "frame_log = frame_logs[0]\n",
    "for k in frame_log.keys():\n",
    "    toprint = \"\\t\\t\" + k\n",
    "    if isinstance(frame_log[k], torch.Tensor):\n",
    "        toprint += \"\\t\" + str(tuple(frame_log[k].shape))\n",
    "    if isinstance(frame_log[k], float):\n",
    "        toprint += \"\\t\" + str(frame_log[k])\n",
    "    print(toprint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11c9c96405994ce5ba4f29a781017766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=3, description='ith_frame', max=6), Output()), _dom_classes=('widget-intâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmap = [\n",
    "    {\"coarse\": \"#039BE5FF\", \"fine\": \"#0D47A1FF\"},       # blue\n",
    "    {\"coarse\": \"#7CB342FF\", \"fine\": \"#33691EFF\"},       # green\n",
    "    {\"coarse\": \"#FB8C00FF\", \"fine\": \"#E64A19FF\"},       # orange\n",
    "    {\"coarse\": \"#BA68C8FF\", \"fine\": \"#4A148CFF\"},       # purple\n",
    "] \n",
    "\n",
    "def series(ith_frame):\n",
    "\n",
    "    frame_log = frame_logs[ith_frame]\n",
    "    \n",
    "    H, W, _ = frame_log[\"rgb_map\"].shape\n",
    "    camera_pose = frame_log[\"c2w\"]\n",
    "    rays_o = frame_log[\"rays_o\"]\n",
    "    rays_d = frame_log[\"rays_d\"]\n",
    "    rgb_map = frame_log[\"rgb_map\"]\n",
    "    depth_map = frame_log[\"depth_map\"]\n",
    "    if \"z_coarse\" in frame_log:\n",
    "        z_coarse = frame_log[\"z_coarse\"]\n",
    "        z_fine = frame_log[\"z_fine\"]\n",
    "    else:\n",
    "        z_coarse = frame_log[\"z_vals\"]\n",
    "        z_fine = np.ndarray(z_coarse.shape)\n",
    "        print(\"No coarse/fine samples. Loading combined values.\")\n",
    "        \n",
    "    near = frame_log[\"near\"]\n",
    "    far = frame_log[\"far\"]\n",
    "\n",
    "    pts_coarse = rays_o[...,None,:] + rays_d[...,None,:] * z_coarse[...,:,None]\n",
    "    pts_fine = rays_o[...,None,:] + rays_d[...,None,:] * z_fine[...,:,None]\n",
    "\n",
    "    ith_rays = [(100, 100), (120, 150), (150, 200), (50, 270)]         # h, w\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    gs = fig.add_gridspec(2, 3)\n",
    "\n",
    "    # Info\n",
    "    info_str =  f\"Exp.:  {path.split('/')[1]}\\n\"\n",
    "    info_str += f\"Step:  {ray_pickles[ith_frame].split('_')[1]}\\n\"\n",
    "    info_str += f\"Near: {near:.2f} m\\n\"\n",
    "    info_str += f\"Far:    {far:.2f} m\"\n",
    "    fig.text(x=0.13, y=0.5, s=info_str)\n",
    "\n",
    "    # RGB img\n",
    "    ax0 = fig.add_subplot(gs[0, 0])\n",
    "    ax0.imshow(rgb_map)\n",
    "    for i, ith_ray in enumerate(ith_rays):\n",
    "        ax0.scatter(*ith_ray[::-1], fc=cmap[i][\"coarse\"], ec=cmap[i][\"fine\"], s=50)\n",
    "    ax0.set_title(\"Predicted RGB Image\")\n",
    "\n",
    "    # Depth img\n",
    "    ax0 = fig.add_subplot(gs[1, 0])\n",
    "    dimg = ax0.imshow(depth_map)\n",
    "    for i, ith_ray in enumerate(ith_rays):\n",
    "        ax0.scatter(*ith_ray[::-1], fc=cmap[i][\"coarse\"], ec=cmap[i][\"fine\"], s=50)\n",
    "    cax = fig.add_axes([0.1, 0.43, 0.2, 0.03])\n",
    "    fig.colorbar(dimg, cax=cax, orientation='horizontal')\n",
    "    ax0.set_title(\"Predicted Depth Map\")\n",
    "\n",
    "    # 3D rays plot\n",
    "    ax1 = fig.add_subplot(gs[:, 1:], projection='3d')\n",
    "    # ax1.computed_zorder = False\n",
    "    ax1.set_title(f\"{len(ith_rays)} Sampled Camera Rays\")\n",
    "\n",
    "    xlim = [-1, 1]\n",
    "    ylim = [-1, 1]\n",
    "    zlim = [-torch.max(z_coarse)//2, torch.max(z_coarse)//2]\n",
    "    ax1.set_xlabel('X')\n",
    "    ax1.set_xlim(*xlim)\n",
    "    ax1.set_ylabel('Y')\n",
    "    ax1.set_ylim(*ylim)\n",
    "    ax1.set_zlabel('Z')\n",
    "    ax1.set_zlim(*zlim)\n",
    "    ax1.set_box_aspect((xlim[1]-xlim[0], ylim[1]-ylim[0], zlim[1]-zlim[0]))       # -> length of 1 in each dimension is visually the equal\n",
    "\n",
    "    # The world coordinate system\n",
    "    axes_len = 0.5\n",
    "    arrow_prop_dict = dict(mutation_scale=20, arrowstyle='simple', shrinkA=0, shrinkB=0)\n",
    "    ax1.add_artist(Arrow3D([0, axes_len], [0, 0], [0, 0], **arrow_prop_dict, color='r'))\n",
    "    ax1.add_artist(Arrow3D([0, 0], [0, axes_len], [0, 0], **arrow_prop_dict, color='b'))\n",
    "    ax1.add_artist(Arrow3D([0, 0], [0, 0], [0, axes_len], **arrow_prop_dict, color='g'))\n",
    "    ax1.text(-0.1, -0.1, 0, r'$0$')\n",
    "    ax1.text(axes_len, 0, 0, r'$x$')\n",
    "    ax1.text(0, axes_len, 0, r'$y$')\n",
    "    ax1.text(0, 0, axes_len, r'$z$')\n",
    "\n",
    "    # Draw the camera coordinate frame\n",
    "    tcx, tcy, tcz, _ = draw_transformed(camera_pose, ax1, arrowstyle='simple', axes_len=0.5, linewidth=1.5, mutation_scale=20, edgecolor=\"black\")\n",
    "    # Draw the camera\n",
    "    draw_cam(rays_o, rays_d, ax1, focal_dist=0.5)       # rays_o and rays_d are already in world-coordinates\n",
    "\n",
    "\n",
    "    # Draw a ray with its samples\n",
    "    for i, ith_ray in enumerate(ith_rays):\n",
    "        draw_ray(rays_o[ith_ray], rays_d[ith_ray], pts_coarse[ith_ray], pts_fine[ith_ray], depth_map[ith_ray], \n",
    "                 near, far, ax=ax1, coarse_c=cmap[i][\"coarse\"], fine_c=cmap[i][\"fine\"])\n",
    "\n",
    "    # Make the legends\n",
    "    lgnd1 = plt.legend(handles=[tcx, tcy, tcz], \n",
    "            labels=[\"X\", \"Y\", \"Z\"], \n",
    "            title=\"Camera pose\", loc=1)\n",
    "    plt.gca().add_artist(lgnd1)\n",
    "\n",
    "    fig.suptitle(f\"{sampling_strategy} in the Global Coordinate System\", )\n",
    "    fig.tight_layout()      \n",
    "    \n",
    "    return\n",
    "\n",
    "inter = interact(series, ith_frame=(0, len(frame_logs)-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'z_vals' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-28bc0021b150>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mz_vals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'z_vals' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = (120, 150)\n",
    "\n",
    "frame_log = frame_logs[0]\n",
    "\n",
    "H, W, _ = frame_log[\"rgb_map\"].shape\n",
    "camera_pose = frame_log[\"c2w\"]\n",
    "rays_o = frame_log[\"rays_o\"]\n",
    "rays_d = frame_log[\"rays_d\"]\n",
    "rgb_map = frame_log[\"rgb_map\"]\n",
    "depth_map = frame_log[\"depth_map\"]\n",
    "if \"z_coarse\" in frame_log:\n",
    "    z_coarse = frame_log[\"z_coarse\"]\n",
    "    z_fine = frame_log[\"z_fine\"].numpy()\n",
    "else:\n",
    "    z_coarse = frame_log[\"z_vals\"]\n",
    "    z_fine = np.ndarray(z_coarse.shape)\n",
    "    print(\"No coarse/fine samples. Loading combined values.\")\n",
    "\n",
    "z_coarse[i].shape, z_fine[i].shape\n",
    "\n",
    "plt.hist(z_coarse[i].numpy(), density=True, bins=20)\n",
    "plt.hist(z_fine[i], density=1, bins=20, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "max() received an invalid combination of arguments - got (out=NoneType, axis=NoneType, ), but expected one of:\n * ()\n * (Tensor other)\n * (int dim, bool keepdim)\n      didn't match because some of the keywords were incorrect: out, axis\n * (name dim, bool keepdim)\n      didn't match because some of the keywords were incorrect: out, axis\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-4dec5222d36b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_coarse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_coarse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dnerf/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2704\u001b[0m     \"\"\"\n\u001b[1;32m   2705\u001b[0m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[0;32m-> 2706\u001b[0;31m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dnerf/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: max() received an invalid combination of arguments - got (out=NoneType, axis=NoneType, ), but expected one of:\n * ()\n * (Tensor other)\n * (int dim, bool keepdim)\n      didn't match because some of the keywords were incorrect: out, axis\n * (name dim, bool keepdim)\n      didn't match because some of the keywords were incorrect: out, axis\n"
     ]
    }
   ],
   "source": [
    "print(np.max(z_coarse), np.min(z_coarse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.2520)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(z_coarse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3375aac2d6777cb84d1d1187d84adfa1daed36a55c3a38ea8e593c91ac430390"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('dnerf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
