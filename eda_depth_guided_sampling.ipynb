{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Exploratory Data Analysis*\n",
    "\n",
    "# Visualizing Depth Guided Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import FancyArrowPatch, FancyArrow, ArrowStyle\n",
    "from mpl_toolkits.mplot3d import proj3d\n",
    "from matplotlib.lines import Line2D\n",
    "import torch\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from run_dnerf_helpers import get_rays\n",
    "from load_deepdeform import load_deepdeform_data, pose_spiral\n",
    "from utils import Arrow3D, draw_transformed, draw_cam, draw_ray\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the validation logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading rays from logs/human_06_mse/step_050000_ray_debug.pickle\n",
      "Loading rays from logs/human_06_mse/step_100000_ray_debug.pickle\n",
      "Loading rays from logs/human_06_mse/step_150000_ray_debug.pickle\n",
      "Loading rays from logs/human_06_mse/step_200000_ray_debug.pickle\n",
      "Loading rays from logs/human_06_mse/step_250000_ray_debug.pickle\n",
      "Loading rays from logs/human_06_mse/step_300000_ray_debug.pickle\n",
      "Loading rays from logs/human_06_mse/step_350000_ray_debug.pickle\n",
      "Loading rays from logs/human_06_mse/step_400000_ray_debug.pickle\n",
      "Logged items (shape/value):\n",
      "\t\trays_o\t(240, 320, 3)\n",
      "\t\trays_d\t(240, 320, 3)\n",
      "\t\trgb_map\t(240, 320, 3)\n",
      "\t\tdepth_map\t(240, 320, 1)\n",
      "\t\tz_coarse\t(240, 320, 64)\n",
      "\t\tz_fine\t(240, 320, 128)\n",
      "\t\tc2w\t(3, 4)\n",
      "\t\tnear\t0.10000000149011612\n",
      "\t\tfar\t3.708749771118164\n"
     ]
    }
   ],
   "source": [
    "path = \"logs/human_06_mse\"\n",
    "\n",
    "sampling_strategy = \"Hierarchical Sampling\"\n",
    "with open(os.path.join(path, \"args.txt\"), \"r\") as f:\n",
    "    for line in f:\n",
    "        if \"use_depth_guided_sampling = True\" in line:\n",
    "            sampling_strategy = \"Depth Guided Sampling\"\n",
    "\n",
    "ray_pickles = sorted([p for p in os.listdir(path) if \".pickle\" in p])\n",
    "frame_logs = []\n",
    "for ray_pickle in ray_pickles:\n",
    "    load_p = os.path.join(path, ray_pickle)\n",
    "    with open(load_p, \"rb\") as f:\n",
    "        print(\"Loading rays from \" + load_p)\n",
    "        frame_logs.append(pickle.load(f))\n",
    "\n",
    "print(\"Logged items (shape/value):\")\n",
    "frame_log = frame_logs[0]\n",
    "for k in frame_log.keys():\n",
    "    toprint = \"\\t\\t\" + k\n",
    "    if isinstance(frame_log[k], torch.Tensor):\n",
    "        toprint += \"\\t\" + str(tuple(frame_log[k].shape))\n",
    "    if isinstance(frame_log[k], float):\n",
    "        toprint += \"\\t\" + str(frame_log[k])\n",
    "    print(toprint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e165c4a1005940709a3fe4519cdf937f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=3, description='ith_frame', max=7), Output()), _dom_classes=('widget-intâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmap = [\n",
    "    {\"coarse\": \"#039BE5FF\", \"fine\": \"#0D47A1FF\"},       # blue\n",
    "    {\"coarse\": \"#7CB342FF\", \"fine\": \"#33691EFF\"},       # green\n",
    "    {\"coarse\": \"#FB8C00FF\", \"fine\": \"#E64A19FF\"},       # orange\n",
    "    {\"coarse\": \"#BA68C8FF\", \"fine\": \"#4A148CFF\"},       # purple\n",
    "] \n",
    "\n",
    "def series(ith_frame):\n",
    "\n",
    "    frame_log = frame_logs[ith_frame]\n",
    "    \n",
    "    H, W, _ = frame_log[\"rgb_map\"].shape\n",
    "    camera_pose = frame_log[\"c2w\"]\n",
    "    rays_o = frame_log[\"rays_o\"]\n",
    "    rays_d = frame_log[\"rays_d\"]\n",
    "    rgb_map = frame_log[\"rgb_map\"]\n",
    "    depth_map = frame_log[\"depth_map\"]\n",
    "    z_coarse = frame_log[\"z_coarse\"]\n",
    "    z_fine = frame_log[\"z_fine\"]\n",
    "    near = frame_log[\"near\"]\n",
    "    far = frame_log[\"far\"]\n",
    "\n",
    "    pts_coarse = rays_o[...,None,:] + rays_d[...,None,:] * z_coarse[...,:,None]\n",
    "    pts_fine = rays_o[...,None,:] + rays_d[...,None,:] * z_fine[...,:,None]\n",
    "\n",
    "    ith_rays = [(100, 100), (120, 150), (150, 200), (50, 270)]         # h, w\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    gs = fig.add_gridspec(2, 3)\n",
    "\n",
    "    # Info\n",
    "    info_str =  f\"Exp.:  {path.split('/')[1]}\\n\"\n",
    "    info_str += f\"Step:  {ray_pickles[ith_frame].split('_')[1]}\\n\"\n",
    "    info_str += f\"Near: {near:.2f} m\\n\"\n",
    "    info_str += f\"Far:    {far:.2f} m\"\n",
    "    fig.text(x=0.13, y=0.5, s=info_str)\n",
    "\n",
    "    # RGB img\n",
    "    ax0 = fig.add_subplot(gs[0, 0])\n",
    "    ax0.imshow(rgb_map)\n",
    "    for i, ith_ray in enumerate(ith_rays):\n",
    "        ax0.scatter(*ith_ray[::-1], fc=cmap[i][\"coarse\"], ec=cmap[i][\"fine\"], s=50)\n",
    "    ax0.set_title(\"Predicted RGB Image\")\n",
    "\n",
    "    # Depth img\n",
    "    ax0 = fig.add_subplot(gs[1, 0])\n",
    "    dimg = ax0.imshow(depth_map)\n",
    "    for i, ith_ray in enumerate(ith_rays):\n",
    "        ax0.scatter(*ith_ray[::-1], fc=cmap[i][\"coarse\"], ec=cmap[i][\"fine\"], s=50)\n",
    "    cax = fig.add_axes([0.1, 0.43, 0.2, 0.03])\n",
    "    fig.colorbar(dimg, cax=cax, orientation='horizontal')\n",
    "    ax0.set_title(\"Predicted Depth Map\")\n",
    "\n",
    "    # 3D rays plot\n",
    "    ax1 = fig.add_subplot(gs[:, 1:], projection='3d')\n",
    "    # ax1.computed_zorder = False\n",
    "    ax1.set_title(f\"{len(ith_rays)} Sampled Camera Rays\")\n",
    "\n",
    "    xlim = [-1, 1]\n",
    "    ylim = [-1, 1]\n",
    "    zlim = [-2, 2]\n",
    "    ax1.set_xlabel('X')\n",
    "    ax1.set_xlim(*xlim)\n",
    "    ax1.set_ylabel('Y')\n",
    "    ax1.set_ylim(*ylim)\n",
    "    ax1.set_zlabel('Z')\n",
    "    ax1.set_zlim(*zlim)\n",
    "    ax1.set_box_aspect((xlim[1]-xlim[0], ylim[1]-ylim[0], zlim[1]-zlim[0]))       # -> length of 1 in each dimension is visually the equal\n",
    "\n",
    "    # The world coordinate system\n",
    "    axes_len = 0.5\n",
    "    arrow_prop_dict = dict(mutation_scale=20, arrowstyle='simple', shrinkA=0, shrinkB=0)\n",
    "    ax1.add_artist(Arrow3D([0, axes_len], [0, 0], [0, 0], **arrow_prop_dict, color='r'))\n",
    "    ax1.add_artist(Arrow3D([0, 0], [0, axes_len], [0, 0], **arrow_prop_dict, color='b'))\n",
    "    ax1.add_artist(Arrow3D([0, 0], [0, 0], [0, axes_len], **arrow_prop_dict, color='g'))\n",
    "    ax1.text(-0.1, -0.1, 0, r'$0$')\n",
    "    ax1.text(axes_len, 0, 0, r'$x$')\n",
    "    ax1.text(0, axes_len, 0, r'$y$')\n",
    "    ax1.text(0, 0, axes_len, r'$z$')\n",
    "\n",
    "    # Draw the camera coordinate frame\n",
    "    tcx, tcy, tcz, _ = draw_transformed(camera_pose, ax1, arrowstyle='simple', axes_len=0.5, linewidth=1.5, mutation_scale=20, edgecolor=\"black\")\n",
    "    # Draw the camera\n",
    "    draw_cam(rays_o, rays_d, ax1, focal_dist=0.5)       # rays_o and rays_d are already in world-coordinates\n",
    "\n",
    "\n",
    "    # Draw a ray with its samples\n",
    "    for i, ith_ray in enumerate(ith_rays):\n",
    "        draw_ray(rays_o[ith_ray], rays_d[ith_ray], pts_coarse[ith_ray], pts_fine[ith_ray], depth_map[ith_ray], \n",
    "                 near, far, ax=ax1, coarse_c=cmap[i][\"coarse\"], fine_c=cmap[i][\"fine\"])\n",
    "\n",
    "    # Make the legends\n",
    "    lgnd1 = plt.legend(handles=[tcx, tcy, tcz], \n",
    "            labels=[\"X\", \"Y\", \"Z\"], \n",
    "            title=\"Camera pose\", loc=1)\n",
    "    plt.gca().add_artist(lgnd1)\n",
    "\n",
    "    fig.suptitle(f\"{sampling_strategy} in the Global Coordinate System\", )\n",
    "    fig.tight_layout()      \n",
    "    \n",
    "    return\n",
    "\n",
    "inter = interact(series, ith_frame=(0, len(frame_logs)-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3375aac2d6777cb84d1d1187d84adfa1daed36a55c3a38ea8e593c91ac430390"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('dnerf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
