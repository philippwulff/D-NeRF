{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Exploratory Data Analysis*\n",
    "\n",
    "# Visualizing the Training Data\n",
    "\n",
    "In this notebook we visualize the camera poses during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import torch\n",
    "import imageio\n",
    "import io\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from ipywidgets import interact\n",
    "\n",
    "from run_dgdnerf_helpers import get_rays, to8b, to8d\n",
    "from utils import load_owndataset_data\n",
    "from utils import Arrow3D, draw_transformed, draw_cam\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "DPI = 200\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.size\": 10,\n",
    "    \"figure.titlesize\": \"x-large\",\n",
    "    \"axes.titlesize\": \"large\",\n",
    "    \"axes.labelsize\": \"small\",\n",
    "    \"xtick.labelsize\": \"small\",\n",
    "    \"ytick.labelsize\": \"small\",\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scene Object Depth: 1.45\n",
      "[Info] Data scaling factor: 1.583984375\n"
     ]
    }
   ],
   "source": [
    "scene_name = \"johannes\"\n",
    "images, depth_maps, poses, times, render_poses, render_times, hwff, i_split = load_owndataset_data(f\"./data/{scene_name}\", True, 1, render_pose_type=\"spherical\")\n",
    "\n",
    "i_train, _, _ = i_split\n",
    "\n",
    "poses = [poses[_] for _ in i_train]\n",
    "images = [images[_] for _ in i_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xlim = [-3, 3]\n",
    "# ylim = [-1, 1]\n",
    "# zlim = [0, 6]\n",
    "xlim = [-1., 1.]\n",
    "ylim = [-1., 1.]\n",
    "zlim = [-1, 1]\n",
    "\n",
    "def series(ith_frame):\n",
    "    pose = poses[ith_frame]\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10), dpi=DPI)\n",
    "    \n",
    "    ax0 = fig.add_subplot(131)\n",
    "    ax0.imshow(images[ith_frame])\n",
    "    ax0.get_xaxis().set_visible(False)\n",
    "    ax0.get_yaxis().set_visible(False)\n",
    "\n",
    "    ax0 = fig.add_subplot(132)\n",
    "    ax0.imshow(depth_maps[ith_frame])\n",
    "    ax0.get_xaxis().set_visible(False)\n",
    "    ax0.get_yaxis().set_visible(False)\n",
    "\n",
    "    ax1 = fig.add_subplot(133, projection='3d')\n",
    "    ax1.set_title(f\"Time = {times[ith_frame]:.2f}\\n\")\n",
    "    ax1.set_xticks([])\n",
    "    ax1.set_yticks([])\n",
    "    ax1.set_zticks([])\n",
    "    # ax1.set_xlabel('X')\n",
    "    # ax1.set_ylabel('Y')\n",
    "    # ax1.set_zlabel('Z')\n",
    "\n",
    "    ax1.set_xlim(*xlim)\n",
    "    ax1.set_ylim(*ylim)\n",
    "    ax1.set_zlim(*zlim)\n",
    "    ax1.set_box_aspect((xlim[1]-xlim[0], ylim[1]-ylim[0], zlim[1]-zlim[0]))       # -> length of 1 in each dimension is visually the equal\n",
    "\n",
    "    # The world coordinate system\n",
    "    arrow_prop_dict = dict(mutation_scale=10, arrowstyle='simple', shrinkA=0, shrinkB=0)\n",
    "    ax1.add_artist(Arrow3D([0, .5], [0, 0], [0, 0], **arrow_prop_dict, color='r'))\n",
    "    ax1.add_artist(Arrow3D([0, 0], [0, .5], [0, 0], **arrow_prop_dict, color='b'))\n",
    "    ax1.add_artist(Arrow3D([0, 0], [0, 0], [0, .5], **arrow_prop_dict, color='g'))\n",
    "    ax1.text(-.1, -.1, 0.0, r'$0$')\n",
    "\n",
    "    tcx, tcy, tcz, _ = draw_transformed(pose, ax1, linestyle=\"--\", axes_len=0.5, mutation_scale=10)\n",
    "    \n",
    "    plt.legend(handles=[Line2D([0], [0], color='r', ls=\"--\"), \n",
    "                        Line2D([0], [0], color='b', ls=\"--\"), \n",
    "                        Line2D([0], [0], color='g', ls=\"--\"), \n",
    "                        Line2D([0], [0], color='black', ls=\"-\")],\n",
    "            labels=[\"X\", \"Y\", \"Z\", \"Camera frustrum\"], \n",
    "            title=\"Training view camera\", \n",
    "            bbox_to_anchor=(1.15, 0.1)\n",
    "            )\n",
    "\n",
    "    # draw camera rays\n",
    "    c2w = torch.Tensor(pose[:3])\n",
    "    H, W, focal_x, focal_y = hwff\n",
    "    i, j = torch.meshgrid(torch.linspace(0, W-1, W), torch.linspace(0, H-1, H), indexing='ij')      # shape [240, 320], [240, 320]\n",
    "    i = i.t()           # pixel coordinates in X-dir\n",
    "    j = j.t()           # in Y-dir\n",
    "    dirs = torch.stack([(i-W*.5)/focal_x, -(j-H*.5)/focal_y, -torch.ones_like(i)], -1)                                          # shape [240, 320, 3]\n",
    "    rays_d = torch.sum(dirs[..., np.newaxis, :] * c2w[:3,:3], -1)  # dot product, equals to: [c2w.dot(dir) for dir in dirs]\n",
    "    rays_o = c2w[:3,-1].expand(rays_d.shape)\n",
    "    draw_cam(rays_o, rays_d, ax1, focal_dist=0.5)       # rays_o and rays_d are already in world-coordinates\n",
    "\n",
    "    ax1.view_init(elev=45., azim=20., vertical_axis='y')        # only works with matplotlib >= 3.5\n",
    "    ax1.dist = 7\n",
    "        \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "119e109203914fb382b40119cb6c3a5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=34, description='ith_frame', max=69), Output()), _dom_classes=('widget-iâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inter = interact(series, ith_frame=(0, len(poses)-1, 1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1608, 725) to (1616, 736) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    }
   ],
   "source": [
    "rgbs = []\n",
    "x1 = None\n",
    "for i in range(len(poses)-1):\n",
    "    fig = series(i)\n",
    "    fig.canvas.draw()\n",
    "    plt.close()\n",
    "    io_buf = io.BytesIO()\n",
    "    fig.savefig(io_buf, format='raw', dpi=DPI)\n",
    "    io_buf.seek(0)\n",
    "    img_arr = np.reshape(np.frombuffer(io_buf.getvalue(), dtype=np.uint8),\n",
    "                        newshape=(int(fig.bbox.bounds[3]), int(fig.bbox.bounds[2]), -1))\n",
    "    io_buf.close()\n",
    "    if not x1:\n",
    "        grey = cv2.cvtColor(img_arr, cv2.COLOR_RGB2GRAY)\n",
    "        thresh = cv2.threshold(grey,226,255,cv2.THRESH_BINARY)[1]\n",
    "        binary = cv2.bitwise_not(thresh)\n",
    "\n",
    "        x1,y1,w,h = cv2.boundingRect(binary)\n",
    "        x2 = x1+w\n",
    "        y2 = y1+h\n",
    "\n",
    "    rgbs.append(img_arr[y1:y2, x1:x2])\n",
    "\n",
    "# change vid size by setting quality [0, 10]\n",
    "imageio.mimwrite('train_frames_w_poses.mp4', np.array(rgbs, dtype=np.uint8), fps=10, quality=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('dgdnerf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a473d2c4ce3776633a637bc4085a1b25a6539806fa99578967f30565e6d27218"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
