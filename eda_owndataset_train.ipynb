{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Exploratory Data Analysis*\n",
    "\n",
    "# Visualizing the Training Data\n",
    "\n",
    "In this notebook we visualize the camera poses during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import torch\n",
    "from ipywidgets import interact\n",
    "\n",
    "from run_dnerf_helpers import get_rays\n",
    "from utils import load_owndataset_data\n",
    "from utils import Arrow3D, draw_transformed, draw_cam\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_name = \"johannes\"\n",
    "images, depth_maps, poses, times, render_poses, render_times, hwff, i_split = load_owndataset_data(f\"./data/{scene_name}\", True, 1, render_pose_type=\"spiral\")\n",
    "\n",
    "i_train, _, _ = i_split\n",
    "\n",
    "poses = [poses[_] for _ in i_train]\n",
    "images = [images[_] for _ in i_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "575fec7aad99427097112e6a99f9fa63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=34, description='ith_frame', max=69), Output()), _dom_classes=('widget-iâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# xlim = [-3, 3]\n",
    "# ylim = [-1, 1]\n",
    "# zlim = [0, 6]\n",
    "xlim = [-1., 1.]\n",
    "ylim = [-1., 1.]\n",
    "zlim = [-1, 1]\n",
    "\n",
    "\n",
    "def series(ith_frame):\n",
    "    pose = poses[ith_frame]\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    ax0 = fig.add_subplot(131)\n",
    "    ax0.imshow(images[ith_frame])\n",
    "    ax0 = fig.add_subplot(132)\n",
    "    ax0.imshow(depth_maps[ith_frame])\n",
    "\n",
    "    ax1 = fig.add_subplot(133, projection='3d')\n",
    "    ax1.set_title(f\"Time = {times[ith_frame]:.2f}\\n\")\n",
    "\n",
    "    ax1.set_xlabel('X')\n",
    "    ax1.set_xlim(*xlim)\n",
    "    ax1.set_ylabel('Y')\n",
    "    ax1.set_ylim(*ylim)\n",
    "    ax1.set_zlabel('Z')\n",
    "    ax1.set_zlim(*zlim)\n",
    "    ax1.set_box_aspect((xlim[1]-xlim[0], ylim[1]-ylim[0], zlim[1]-zlim[0]))       # -> length of 1 in each dimension is visually the equal\n",
    "\n",
    "    # The world coordinate system\n",
    "    arrow_prop_dict = dict(mutation_scale=10, arrowstyle='simple', shrinkA=0, shrinkB=0)\n",
    "    ax1.add_artist(Arrow3D([0, .5], [0, 0], [0, 0], **arrow_prop_dict, color='r'))\n",
    "    ax1.add_artist(Arrow3D([0, 0], [0, .5], [0, 0], **arrow_prop_dict, color='b'))\n",
    "    ax1.add_artist(Arrow3D([0, 0], [0, 0], [0, .5], **arrow_prop_dict, color='g'))\n",
    "    ax1.text(-.1, -.1, 0.0, r'$0$')\n",
    "\n",
    "    tcx, tcy, tcz, _ = draw_transformed(pose, ax1, linestyle=\"--\", axes_len=0.5, mutation_scale=10)\n",
    "\n",
    "    # Draw the training camera coordinate frame\n",
    "    #tcx, tcy, tcz, _ = draw_transformed(pose, ax1, arrowstyle='simple', axes_len=0.7, linewidth=1.5, mutation_scale=20, edgecolor=\"black\")\n",
    "\n",
    "#     lgnd1 = plt.legend(handles=[tcx, tcy, tcz], \n",
    "#             labels=[\"X\", \"Y\", \"Z\"], \n",
    "#             title=\"Global coordinate frame\", loc=1)\n",
    "    plt.legend(handles=[Line2D([0], [0], color='r', ls=\"--\"), \n",
    "                        Line2D([0], [0], color='b', ls=\"--\"), \n",
    "                        Line2D([0], [0], color='g', ls=\"--\"), \n",
    "                        Line2D([0], [0], color='black', ls=\"-\")],\n",
    "            labels=[\"X\", \"Y\", \"Z\", \"Camera frustrum\"], \n",
    "            title=\"Training view camera\", \n",
    "            bbox_to_anchor=(1.7, 0.3))\n",
    "\n",
    "    # draw camera rays\n",
    "    c2w = torch.Tensor(pose[:3])\n",
    "    H, W, focal_x, focal_y = hwff\n",
    "    i, j = torch.meshgrid(torch.linspace(0, W-1, W), torch.linspace(0, H-1, H), indexing='ij')      # shape [240, 320], [240, 320]\n",
    "    i = i.t()           # pixel coordinates in X-dir\n",
    "    j = j.t()           # in Y-dir\n",
    "    dirs = torch.stack([(i-W*.5)/focal_x, -(j-H*.5)/focal_y, -torch.ones_like(i)], -1)                                          # shape [240, 320, 3]\n",
    "    rays_d = torch.sum(dirs[..., np.newaxis, :] * c2w[:3,:3], -1)  # dot product, equals to: [c2w.dot(dir) for dir in dirs]\n",
    "    rays_o = c2w[:3,-1].expand(rays_d.shape)\n",
    "    draw_cam(rays_o, rays_d, ax1, focal_dist=0.5)       # rays_o and rays_d are already in world-coordinates\n",
    "\n",
    "    ax1.view_init(elev=30., azim=20., vertical_axis='y')        # only works with matplotlib >= 3.5\n",
    "    ax1.dist = 6.2\n",
    "    \n",
    "    fig.tight_layout()\n",
    "\n",
    "inter = interact(series, ith_frame=(0, len(poses)-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('dgdnerf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a473d2c4ce3776633a637bc4085a1b25a6539806fa99578967f30565e6d27218"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
